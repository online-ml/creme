{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression is about predicting a numeric output for a given sample. A labeled regression sample is made up of a bunch of features and a number. The number is usually continuous, but it may also be discrete. We'll use the Trump approval rating dataset as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T02:36:43.314802Z",
     "iopub.status.busy": "2024-11-25T02:36:43.314616Z",
     "iopub.status.idle": "2024-11-25T02:36:44.208948Z",
     "shell.execute_reply": "2024-11-25T02:36:44.208347Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Donald Trump approval ratings.\n",
       "\n",
       "This dataset was obtained by reshaping the data used by FiveThirtyEight for analyzing Donald\n",
       "Trump's approval ratings. It contains \u001b[1;36m5\u001b[0m features, which are approval ratings collected by\n",
       "\u001b[1;36m5\u001b[0m polling agencies. The target is the approval rating from FiveThirtyEight's model. The goal of\n",
       "this task is to see if we can reproduce FiveThirtyEight's model.\n",
       "\n",
       "    Name  TrumpApproval                                                     \n",
       "    Task  Regression                                                        \n",
       " Samples  \u001b[1;36m1\u001b[0m,\u001b[1;36m001\u001b[0m                                                             \n",
       "Features  \u001b[1;36m6\u001b[0m                                                                 \n",
       "  Sparse  \u001b[3;91mFalse\u001b[0m                                                             \n",
       "    Path  \u001b[35m/home/runner/work/river/river/river/datasets/\u001b[0m\u001b[95mtrump_approval.csv.gz\u001b[0m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from river import datasets\n",
    "\n",
    "dataset = datasets.TrumpApproval()\n",
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is a streaming dataset which can be looped over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T02:36:44.211047Z",
     "iopub.status.busy": "2024-11-25T02:36:44.210635Z",
     "iopub.status.idle": "2024-11-25T02:36:44.218321Z",
     "shell.execute_reply": "2024-11-25T02:36:44.217781Z"
    }
   },
   "outputs": [],
   "source": [
    "for x, y in dataset:\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T02:36:44.220438Z",
     "iopub.status.busy": "2024-11-25T02:36:44.220084Z",
     "iopub.status.idle": "2024-11-25T02:36:44.226061Z",
     "shell.execute_reply": "2024-11-25T02:36:44.225493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'ordinal_date'\u001b[0m: \u001b[1;36m736389\u001b[0m,\n",
       "    \u001b[32m'gallup'\u001b[0m: \u001b[1;36m43.843213\u001b[0m,\n",
       "    \u001b[32m'ipsos'\u001b[0m: \u001b[1;36m46.19925042857143\u001b[0m,\n",
       "    \u001b[32m'morning_consult'\u001b[0m: \u001b[1;36m48.318749\u001b[0m,\n",
       "    \u001b[32m'rasmussen'\u001b[0m: \u001b[1;36m44.104692\u001b[0m,\n",
       "    \u001b[32m'you_gov'\u001b[0m: \u001b[1;36m43.636914000000004\u001b[0m\n",
       "\u001b[1m}\u001b[0m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(dataset))\n",
    "x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regression model's goal is to learn to predict a numeric target `y` from a bunch of features `x`. We'll attempt to do this with a nearest neighbors model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T02:36:44.227932Z",
     "iopub.status.busy": "2024-11-25T02:36:44.227586Z",
     "iopub.status.idle": "2024-11-25T02:36:44.245621Z",
     "shell.execute_reply": "2024-11-25T02:36:44.245171Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;36m0.0\u001b[0m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from river import neighbors\n",
    "\n",
    "model = neighbors.KNNRegressor()\n",
    "model.predict_one(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model hasn't been trained on any data, and therefore outputs a default value of 0.\n",
    "\n",
    "The model can be trained on the sample, which will update the model's state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T02:36:44.247391Z",
     "iopub.status.busy": "2024-11-25T02:36:44.247076Z",
     "iopub.status.idle": "2024-11-25T02:36:44.249811Z",
     "shell.execute_reply": "2024-11-25T02:36:44.249246Z"
    }
   },
   "outputs": [],
   "source": [
    "model.learn_one(x, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try to make a prediction on the same sample, we can see that the output is different, because the model has learned something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T02:36:44.251541Z",
     "iopub.status.busy": "2024-11-25T02:36:44.251237Z",
     "iopub.status.idle": "2024-11-25T02:36:44.255921Z",
     "shell.execute_reply": "2024-11-25T02:36:44.255383Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;36m43.75505\u001b[0m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_one(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, an online model makes a prediction, and then learns once the ground truth reveals itself. The prediction and the ground truth can be compared to measure the model's correctness. If you have a dataset available, you can loop over it, make a prediction, update the model, and compare the model's output with the ground truth. This is called progressive validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T02:36:44.257687Z",
     "iopub.status.busy": "2024-11-25T02:36:44.257383Z",
     "iopub.status.idle": "2024-11-25T02:36:47.127198Z",
     "shell.execute_reply": "2024-11-25T02:36:47.126580Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MAE: \u001b[1;36m0.310353\u001b[0m"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from river import metrics\n",
    "\n",
    "model = neighbors.KNNRegressor()\n",
    "\n",
    "metric = metrics.MAE()\n",
    "\n",
    "for x, y in dataset:\n",
    "    y_pred = model.predict_one(x)\n",
    "    model.learn_one(x, y)\n",
    "    metric.update(y, y_pred)\n",
    "    \n",
    "metric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a common way to evaluate an online model. In fact, there is a dedicated `evaluate.progressive_val_score` function that does this for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T02:36:47.129251Z",
     "iopub.status.busy": "2024-11-25T02:36:47.128928Z",
     "iopub.status.idle": "2024-11-25T02:36:50.028481Z",
     "shell.execute_reply": "2024-11-25T02:36:50.027903Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MAE: \u001b[1;36m0.310353\u001b[0m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from river import evaluate\n",
    "\n",
    "model = neighbors.KNNRegressor()\n",
    "metric = metrics.MAE()\n",
    "\n",
    "evaluate.progressive_val_score(dataset, model, metric)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e6e87bad9c8c768904c061eafcb4f6739260ff8bb57f302c215ab258ded773dc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('river')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
