{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipelines are an integral part of River. We encourage their usage and apply them in many of their examples.\n",
    "\n",
    "The `compose.Pipeline` contains all the logic for building and applying pipelines. A pipeline is essentially a list of estimators that are applied in sequence. The only requirement is that the first `n - 1` steps be transformers. The last step can be a regressor, a classifier, a clusterer, etc.\n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T17:49:52.864965Z",
     "iopub.status.busy": "2023-12-04T17:49:52.864389Z",
     "iopub.status.idle": "2023-12-04T17:49:53.144412Z",
     "shell.execute_reply": "2023-12-04T17:49:53.144042Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from river import compose\n",
    "from river import linear_model\n",
    "from river import preprocessing\n",
    "from river import feature_extraction\n",
    "\n",
    "model = compose.Pipeline(\n",
    "    preprocessing.StandardScaler(),\n",
    "    feature_extraction.PolynomialExtender(),\n",
    "    linear_model.LinearRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the `|` operator, as so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T17:49:53.146332Z",
     "iopub.status.busy": "2023-12-04T17:49:53.146215Z",
     "iopub.status.idle": "2023-12-04T17:49:53.154883Z",
     "shell.execute_reply": "2023-12-04T17:49:53.154651Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = (\n",
    "    preprocessing.StandardScaler() |\n",
    "    feature_extraction.PolynomialExtender() |\n",
    "    linear_model.LinearRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, equally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T17:49:53.156607Z",
     "iopub.status.busy": "2023-12-04T17:49:53.156514Z",
     "iopub.status.idle": "2023-12-04T17:49:53.165628Z",
     "shell.execute_reply": "2023-12-04T17:49:53.165348Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = preprocessing.StandardScaler() \n",
    "model |= feature_extraction.PolynomialExtender()\n",
    "model |= linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pipeline has a `_repr_html_` method, which can be used to visualize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T17:49:53.167122Z",
     "iopub.status.busy": "2023-12-04T17:49:53.167045Z",
     "iopub.status.idle": "2023-12-04T17:49:53.180439Z",
     "shell.execute_reply": "2023-12-04T17:49:53.180202Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`compose.Pipeline` implements a `learn_one` method which in sequence calls the `learn_one` of each step and a `predict_one` (resp `predict_proba_one`) method which calls `transform_one` on the first `n - 1` steps and `predict_one` (resp `predict_proba_one`) on the last step.\n",
    "\n",
    "Here is a small example to illustrate the previous point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T17:49:53.181786Z",
     "iopub.status.busy": "2023-12-04T17:49:53.181717Z",
     "iopub.status.idle": "2023-12-04T17:49:53.319962Z",
     "shell.execute_reply": "2023-12-04T17:49:53.319706Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from river import datasets\n",
    "\n",
    "dataset = iter(datasets.TrumpApproval())\n",
    "x, y = next(dataset)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn_one(x, y)\n",
    "\n",
    "x, y = next(dataset)\n",
    "model.learn_one(x, y)\n",
    "\n",
    "x, _ = next(dataset)\n",
    "model.predict_one(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each component/step of the pipeline has been updated with the new data point. \n",
    "\n",
    "A pipeline is a very powerful tool that can be used to chain together multiple steps in a machine learning workflow.\n",
    "\n",
    "Notice that it is also possible to call `transform_one` with a pipeline, this method will run `transform_one` of each transformer in it, and return the result of the last transformer (which is thus the penultimate step):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T17:49:53.332637Z",
     "iopub.status.busy": "2023-12-04T17:49:53.332562Z",
     "iopub.status.idle": "2023-12-04T17:49:53.341944Z",
     "shell.execute_reply": "2023-12-04T17:49:53.341509Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.transform_one(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many cases, you might want to connect a step to multiple steps. For instance, you might to extract different kinds of features from a single input. An elegant way to do this is to use a `compose.TransformerUnion`. Essentially, the latter is a list of transformers who's results will be merged into a single `dict` when `transform_one` is called.\n",
    "\n",
    "As an example let's say that we want to apply a `feature_extraction.RBFSampler` as well as the `feature_extraction.PolynomialExtender`. This may be done as so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T17:49:53.357462Z",
     "iopub.status.busy": "2023-12-04T17:49:53.357331Z",
     "iopub.status.idle": "2023-12-04T17:49:53.369477Z",
     "shell.execute_reply": "2023-12-04T17:49:53.369159Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = (\n",
    "    preprocessing.StandardScaler() |\n",
    "    (feature_extraction.PolynomialExtender() + feature_extraction.RBFSampler()) |\n",
    "    linear_model.LinearRegression()\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `+` symbol acts as a shorthand notation for creating a `compose.TransformerUnion`, which means that we could have declared the above pipeline as so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T17:49:53.371204Z",
     "iopub.status.busy": "2023-12-04T17:49:53.371072Z",
     "iopub.status.idle": "2023-12-04T17:49:53.381553Z",
     "shell.execute_reply": "2023-12-04T17:49:53.381303Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = (\n",
    "    preprocessing.StandardScaler() |\n",
    "    compose.TransformerUnion(\n",
    "        feature_extraction.PolynomialExtender(),\n",
    "        feature_extraction.RBFSampler()\n",
    "    ) |\n",
    "    linear_model.LinearRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipelines provide the benefit of removing a lot of cruft by taking care of tedious details for you. They also enable to clearly define what steps your model is made of.\n",
    "\n",
    "Finally, having your model in a single object means that you can move it around more easily.\n",
    "\n",
    "Note that you can include user-defined functions in a pipeline by using a `compose.FuncTransformer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning during predict\n",
    "\n",
    "In online macine learning, we can update the unsupervised parts of our model when a sample arrives. We don't _really_ have to wait for the ground truth to arrive in order to update unsupervised estimators that don't depend on it.\n",
    "\n",
    "In other words, in a pipeline, `learn_one` updates the supervised parts, whilst `predict_one` (or `predict_proba_one` for that matter) **can** update the unsupervised parts. \n",
    "\n",
    "In river, we can achieve this behavior using a dedicated context manager: `compose.learn_during_predict`.\n",
    "\n",
    "Here is the same example as before, with the only difference of activating the such learning during predict behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = (\n",
    "    preprocessing.StandardScaler() |\n",
    "    feature_extraction.PolynomialExtender() |\n",
    "    linear_model.LinearRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with compose.learn_during_predict():\n",
    "\n",
    "    x, y = next(dataset)\n",
    "    model.predict_one(x)\n",
    "\n",
    "    x, y = next(dataset)\n",
    "    model.predict_one(x)\n",
    "\n",
    "model['StandardScaler'].means, model['StandardScaler'].vars "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `predict_one` within this context will update each transformer of the pipeline. For instance here we can see that the mean and the variance each feature of the standard scaler step have been updated.\n",
    "\n",
    "On the other hand, the supervised part of our pipeline, the linear regression, has not been updated or learned anything yet. Hence the prediction on any sample will be nil because each weight is still equal to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_one(x), model[\"LinearRegression\"].weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
